{"meta":{"title":"qiaofeng-fangxianhao","subtitle":"书山有路勤为径","description":null,"author":"qiaofeng-fangxianhao","url":"http://qiaofengfangxh.top","root":"/"},"pages":[{"title":"","date":"2020-08-28T07:35:20.196Z","updated":"2019-07-17T08:33:42.000Z","comments":false,"path":"categories/index.html","permalink":"http://qiaofengfangxh.top/categories/index.html","excerpt":"","text":""},{"title":"","date":"2020-04-21T08:22:42.411Z","updated":"2019-07-17T08:33:58.000Z","comments":false,"path":"tags/index.html","permalink":"http://qiaofengfangxh.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Java设计模式-观察者模式","slug":"Java观察者模式","date":"2020-08-28T07:30:16.000Z","updated":"2020-09-11T12:59:26.407Z","comments":true,"path":"2020/08/28/Java观察者模式/","link":"","permalink":"http://qiaofengfangxh.top/2020/08/28/Java观察者模式/","excerpt":"","text":"观察者模式（Observer Pattern）定义了对象之间的一对多依赖，让多个观察者对象同时监听一个主题对象，当主题对象发生状态变化时，它的（被观察者）的所有依赖者（观察者）都会收到通知并做做出自动更新 java观察者设计模式java观察者模式的定义观察者模式（Observer Pattern）定义了对象之间的一对多依赖，让多个观察者对象同时监听一个主题对象，当主题对象发生状态变化时，它的（被观察者）的所有依赖者（观察者）都会收到通知并做做出自动更新的业务操作，观察者模式属于行为型模式，观察者模式也可以称为《发布/订阅模式》 观察者模式的结构在实际使用中，我们不能要注意具体目标对象和具体观察者对象之间不能直接调用，否则将使两者之间紧密耦合起来，这违反了面向对象的设计原则，观察者模式的角色如下： 抽象主题角色抽象主题角色也叫抽象目标类，它提供了一个用于保存观察者对象的聚集类和增加、删除观察者对象的方法，以及通知所有观察者的抽象方法。一般我们定义成抽象类实现具体主题角色具体主题角色也叫具体目标类，它实现了抽象主题里面的通知方法，当具体主题发生状态变化时去通知所有注册过的多个观察者对象抽象观察者角色抽象观察者角色包含了一个抽象的更新方法，它接收到具体主题变化通知时候被调用(具体主题角色里面的通知方法里面去触发这个方法),这个我们一般定义成接口或者抽象类具体观察者角色具体观察者角色实现抽象观察者中定义的抽象方法，以便在得到目主题标的更改通知时根据自己的实际业务需求做一些个性化的更新操作观察者模式案例演示在这里我们拿微信公众号做观察者模式案例讲解：假设微信用户就是观察者，微信公众号是被观察者，有多个的微信用户关注了&lt;&lt;程序员的编程人生&gt;&gt;这个公众号，当这个公众号发布新的消息时候就会自动通知给这些订阅的微信用户。 抽象被观察者： 抽象主题对象有三个核心接口：attach(增加观察者)、detach(删除观察者)、notify(通知观察者) public interface Subject { /** * 增加订阅者 * @param observer */ public void attach(Observer observer); /** * 删除订阅者 * @param observer */ public void detach(Observer observer); /** * 通知订阅者做更新 * @param message */ public void notify(String message); }具体被观察者： 微信公众号是具体主题（具体被观察者），里面存储了订阅该公众号的微信用户（观察者），并实现了抽象主题中的三个接口。 public class SubscriptionSubject implements Subject { //储存订阅公众号的微信用户 private ArrayList&lt;Observer&gt; weixinUserlist = new ArrayList&lt;Observer&gt;(); @Override public void attach(Observer observer) { weixinUserlist.add(observer); } @Override public void detach(Observer observer) { weixinUserlist.remove(observer); } @Override public void notify(String message) { for (Observer observer : weixinUserlist) { observer.update(message); } } }抽象观察者： 里面定义了一个更新方法： public interface Observer { /** * 接收被观察者发布的消息做更新操作 * @param message */ public void update(String message); }具体观察者： 订阅过&lt;&lt;程序员的编程人生&gt;&gt;这个公众号的微信用户就是具体观察者，里面实现了抽象观察者定义的更新接口。 public class WeixinUser implements Observer { private String name;//微信用户 public WeixinUser(String name) { this.name = name; } @Override public void update(String message) { System.out.println(name + &quot;-&quot; + message); } }最后，我们来进行客户端的调用，并进行执行结果的演示： public class Client { public static void main(String[] args) { SubscriptionSubject mSubscriptionSubject=new SubscriptionSubject(); //创建微信用户 WeixinUser user1=new WeixinUser(&quot;杨影枫&quot;); WeixinUser user2=new WeixinUser(&quot;月眉儿&quot;); WeixinUser user3=new WeixinUser(&quot;紫轩&quot;); //订阅公众号 mSubscriptionSubject.attach(user1); mSubscriptionSubject.attach(user2); mSubscriptionSubject.attach(user3); //公众号更新发出消息给订阅的微信用户 mSubscriptionSubject.notify(&quot;刘望舒的专栏更新了&quot;); } } 执行结果： 杨影枫-刘望舒的专栏更新了 月眉儿-刘望舒的专栏更新了 紫轩-刘望舒的专栏更新了JDK包中的观察者模式 在 Java 中，通过 java.util.Observable 类和 java.util.Observer 接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例。 Observable类： Observable 类是抽象目标类，它有一个 Vector 向量，用于保存所有要通知的观察者对象，下面来介绍它最重要的3个方法： 1. void addObserver(Observer o) ：用于将新的观察者对象添加到向量中。 2. void notifyObservers(Object arg) ：调用向量中的所有观察者对象的 update。方法，通知它们数据发生改变。通常越晚加入向量的观察者越先得到通知。 3. void setChange() ：用来设置一个 boolean 类型的内部标志位，注明目标对象发生了变化。当它为真时，notifyObservers() 才会通知观察者。Observer 接口Observer 接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用 void update(Observable o,Object arg) 方法，那么实现过Observer接口的具体观察者们就会做对应的更新操作。 观察者模式的优缺点优点观察者模式的优点有： 1. 观察者模式在观察者和被观察者之间建立了一个抽象的耦合，被观察者和观察者共同实现一个抽象的观察者的接口，并不知道一个具体的观察者是谁，实现了解耦的功效，符合依赖倒置原则 2. 观察者模式支持广播通讯，也就是我们常说的发布和订阅机制，被观察者发布一个信息，所有感兴趣和订阅过这个抽象观察接口的观察者都会收到信息，从而做相应的更新业务操作缺点观察者模式的缺点有： 1. 如果一个被观察者有很多直接或者间接的观察者的时候，这些观察者有很多其他的细节依赖，将所有观察者通知到花费时间多，也就是我们说的代码执行效率差，提高了程序的时间消耗和复杂度 2. 如果在多个被观察者之间有循环依赖，被观察者做发布操作的话，那么这些观察者就会触发他们的循环依赖的方法调用，导致代码死循环，系统宕机，这点是非常危险的观察者模式的适用场景观察者模式的适用场景有以下： 1. 当一个抽象模型包含两个方面内容的时候，其中一个方面依赖于另一个方面的状态变化才会对自己做出自动更新操作的时候 2. 一个或者多个对象的变化依赖一个共同的对象的变化，也就是我们说的第一点 3. 实现类似广播机制的功能，不需要知道具体的收听广播的对象，只需要发布广播，系统中感兴趣（订阅过）的对象会自动接收这个广播，并且自动做出相应的业务更新操作","categories":[{"name":"java","slug":"java","permalink":"http://qiaofengfangxh.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://qiaofengfangxh.top/tags/java/"},{"name":"设计模式","slug":"设计模式","permalink":"http://qiaofengfangxh.top/tags/设计模式/"},{"name":"观察者模式","slug":"观察者模式","permalink":"http://qiaofengfangxh.top/tags/观察者模式/"}]},{"title":"线程池ThreadPoolExecutor源码学习和总结","slug":"线程池ThreadPoolExecutor源码分析","date":"2020-07-25T07:30:16.000Z","updated":"2020-09-11T12:28:44.540Z","comments":true,"path":"2020/07/25/线程池ThreadPoolExecutor源码分析/","link":"","permalink":"http://qiaofengfangxh.top/2020/07/25/线程池ThreadPoolExecutor源码分析/","excerpt":"","text":"线程池的作用Thread其实是一种特别重量级的资源，创建、启动、销毁其实都是比较耗费系统资源的，因此对于线程的重复利用是一种特别好的编程习惯，加之程序中可创建的线程数量是有限的，一般系统的性能越好，可以创建的线程数目就越多。但是当线程创建的越多时，系统的性能就会越差。自JDK1.5起，Util包就提供了ExecutorService线程池的实现，主要目的是为了重复利用线程，提高系统的效率。 线程池的使用使用ThreadPoolExecutor来创建一个线程池： 12new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit,workQueue, handler); 创建一个线程池时需要传入几个参数，各参数的作用如下： corePoolSize：线程池的基本大小 提交一个任务到线程池时，如果当前执行的任务数小于线程池基本大小，线程池会新创建一个线程来执行任务。 workQueue：工作任务队列 当线程池的大小已经超过核心线程数后，新提交的任务保存至阻塞队列，阻塞队列的选择有以下几种： 1234ArrayBlockingQueue：基于数组结构的有界阻塞队列，此队列按FIFO原则对元素进行排序。LinkedBlockingQueue：基于链表结构的阻塞队列，此队列按FIFO原则对元素进行排序。SynchronousQueue：不存储元素的阻塞队列。每个插入操作必须等待一个移除操作，否则插入操作一直处于阻塞状态。PriorityBlockingQueue：一个具有优先级的无界阻塞队列。 maximumPoolSize：线程池最大数量 如果提交的任务不能保存到队列中(队列已满)，并且线程池的大小小于最大线程数，则线程池会再创建新的线程执行任务。 keepAliveTime：线程活跃存活时间 当线程池的工作线程空闲后，在活跃时间内没有执行任务，则对该线程进行回收。 unit：线程活动保持时间的单位 通过TimeUnit类选择的单位有天、小时、分钟、毫秒、微秒和纳秒。 handler：饱和策略 当提交的任务不能保存到队列中且线程池的大小已经不小于最大线程数，那么说明该线程池处于饱和状态，此时需要采取一种饱和策略来处理新提交的任务。 饱和策略的默认选择为AbortPolicy，表示当线程池饱和时抛出异常。线程池框架还提供了以下3种策略： 123CallerRunsPolicy：直接在调用者线程中执行该任务。DiscardOldestPolicy：执行队列的poll()方法，然后执行线程池的execute()方法再次提交到线程池。DiscardPolicy：不进行任何处理，也就是将任务直接丢弃了。 如果想要扩展饱和策略，可以实现RejectedExecutionHandler接口自定义饱和策略。 线程池的实现原理当向线程池提交一个任务之后，线程池的简单处理流程如下： 如果线程池当前运行的线程没有超过核心线程数，则创建新线程来执行任务；否则将任务添加入队列中。 如果队列已满，则判断线程池当前运行的线程是否少于最大线程数，如果少于最大线程数，则创建新线程来执行任务。 如果创建新线程将使当前运行的线程超出最大线程数，将执行饱和策略。 线程池源码分析使用线程池的execute()向线程池提交任务，先从execute()方法开始作为查看源码入口 execute()execute()方法源码如下： 123456789101112131415161718192021222324public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); //如果线程池当前运行的线程少于核心线程数，则创建新线程来执行任务 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; //如果线程池当前运行的线程不少于核心线程数，则将任务添加入队列中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); //再次检查是否需要添加新的线程 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //如果线程池处于非运行状态,执行饱和策略 //如果之前的线程已被销毁，新建一个线程 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //如果队列已满，则创建新的线程来处理任务 else if (!addWorker(command, false)) reject(command); //如果创建新线程失败了，执行饱和策略&#125; addWorker()当工作线程数小于核心线程数的时候，会调用 addWorker()方法创建一个工作线程，简单来讲就是使用cas操作将工作线程数递增，然后新建一个线程并启动。源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: //goto for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); //判断线程池是否处于运行状态,处于SHUTDOWN状态时判断队列是否为空 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); //获得工作线程数 //如果工作线程数大于核心线程数或大于最大线程数，则返回false表示不能再添加新线程 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; //cas增加工作线程数,cas失败则重试 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // 重新获取ctl的值 //如果线程状态发生变化,则重试 if (runStateOf(c) != rs) continue retry; &#125; &#125; boolean workerStarted = false; //工作线程启动标识 boolean workerAdded = false; //工作线程添加成功标识 Worker w = null; try &#123; w = new Worker(firstTask); //构建一个Worker,传入Runnable对象 final Thread t = w.thread; //从worker中取出线程 if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); //使用重入锁，避免并发问题 try &#123; int rs = runStateOf(ctl.get()); //只有线程池是运行状态或是(SHUTDOWN且firstTask为空)，才添加到workers中 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; //判断线程是否活跃 if (t.isAlive()) throw new IllegalThreadStateException(); workers.add(w); //将新创建的Worker添加到workers中 int s = workers.size(); //集合中的工作线程数 //如果集合中的工作线程数大于最大线程数 if (s &gt; largestPoolSize) largestPoolSize = s; //更新线程池出现过的最大线程数 workerAdded = true; //工作线程添加成功标识 &#125; &#125; finally &#123; mainLock.unlock(); //释放锁 &#125; //如果worker添加成功则启动线程 if (workerAdded) &#123; t.start(); workerStarted = true; //工作线程启动标识 &#125; &#125; &#125; finally &#123; if (! workerStarted) //如果添加失败，递减实际工作线程数,因为方法开始时增加了工作线程数 addWorkerFailed(w); &#125; return workerStarted; //返回结果&#125; Worker类addWorker()方法中构建了一个Worker类，并且把firstTask 封装到 worker 中，Worker类的源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; private static final long serialVersionUID = 6138294804551838833L; /** 这就是实际运行的工作线程 */ final Thread thread; /** 这是需要执行的任务 */ Runnable firstTask; /** 线程完成的任务数 */ volatile long completedTasks; Worker(Runnable firstTask) &#123; setState(-1); // 初始状态-1,防止runWorker()前中断 this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; public void run() &#123; runWorker(this); &#125; protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; 从源码中可以看到，worker中保存了一个实际执行任务的线程thread，以及初始化时要被执行的任务firstTask；最终执行任务时，实际是调用了runWorker()方法。 worker类继承了AbstractQueuedSynchronizer(AQS)，使用AQS实现了独占锁的功能，但是它的tryAcquire()方法是不允许重入的，它的独占锁作用如下： 当前线程拥有独占锁，那就说明当前线程正在执行任务，当前线程不该被中断 如果当前线程没有拥有独占锁，说明当前线程处于空闲状态，可以对该线程进行中断操作 addWorkerFailed()在addWorker()方法中，如果添加 Worker失败则调用addWorkerFailed()方法做失败后的处理，源码如下： 123456789101112private void addWorkerFailed(Worker w) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; if (w != null) workers.remove(w); decrementWorkerCount(); tryTerminate(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 如果添加 Worker失败后，判断Worker是否已经构造好了，如果Worker不为空则从workers中删除，且原子递减核心线程数的数量，之后执行tryTerminate()方法尝试结束线程池。 runWorker()调用Worker类的run()方法时，实际会调用runWorker()方法执行任务，该方法源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); //表示允许中断 boolean completedAbruptly = true; try &#123; //循环执行任务,如果task为空,调用getTask()方法获取task while (task != null || (task = getTask()) != null) &#123; w.lock(); //加锁使得shutdown()方法不会终止正在执行任务的worker // 线程池为stop时不接受新任务，不执行任务队列的任务，且中断正在执行的任务 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); //可以继承ThreadpoolExecutor重写 Throwable thrown = null; try &#123; task.run(); //执行任务的run()方法 &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); //可以继承ThreadpoolExecutor重写 &#125; &#125; finally &#123; task = null; //将完成的任务置空以便下一次循环 w.completedTasks++; //增加完成任务数 w.unlock(); //释放锁 &#125; &#125; completedAbruptly = false; &#125; finally &#123; //删除worker,及判断释放补充新的worker processWorkerExit(w, completedAbruptly); &#125;&#125; runWorker()方法主要处理了以下两件事： 循环执行task任务，如果task为空则调用getTask()方法获取task任务 如果getTask()方法取得的任务依然位空，则runWorker()方法执行完毕 getTask()在runWorker()方法中，worker 线程调用getTask()方法从阻塞队列中获取需要执行的任务，源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940private Runnable getTask() &#123; boolean timedOut = false; //判断是否超时 for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); //判断线程池在shutdown状态时队列是否为空 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; //线程池在shutdown状态时队列为空或线程池为stop状态 &#125; int wc = workerCountOf(c); //如果线程池中的线程数量大于核心线程数量,则需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; //如果timed为true,表示需要进行超时控制 //通过阻塞队列的poll()方法实现超时控制,参数则为keepaliveTime Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); //如果取到的任务为空,则表示超时,否则返回取到的任务 if (r != null) return r; timedOut = true; //超时回收标记 &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; processWorkerExit()runWorker()方法中的的 while 循环执行完毕以后，在 finally 块中会调用 processWorkerExit()方法来销毁工作线程。processWorkerExit()方法源码如下： 123456789101112131415161718192021222324252627private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; if (completedAbruptly) //判断是否调整工作线程数 decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; //结束 &#125; addWorker(null, false); &#125;&#125; 到此为止，从执行execute()方法提交任务开始，创建worke线程到执行任务以及最后到销毁线程的全部过程就结束。","categories":[{"name":"java","slug":"java","permalink":"http://qiaofengfangxh.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://qiaofengfangxh.top/tags/java/"},{"name":"线程池","slug":"线程池","permalink":"http://qiaofengfangxh.top/tags/线程池/"}]},{"title":"Redis-持久化数据","slug":"Redis-持久化数据","date":"2020-07-19T08:30:16.000Z","updated":"2020-09-11T12:29:28.255Z","comments":true,"path":"2020/07/19/Redis-持久化数据/","link":"","permalink":"http://qiaofengfangxh.top/2020/07/19/Redis-持久化数据/","excerpt":"","text":"Redis被称为是内存数据库，那是因为它会将其所有数据存储在内存里，因此Redis具有强劲的速度性能，但是，也正因为数据存储在内存中，当Redis重启后，所有存储在内存的数据就会丢失。为了使得数据持久化，Redis提供了两种方式：RDB方式和AOF方式。 RDB方式RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时，Redis会自动将内存中所有的数据生成一份副本并存储在硬盘中，这个过程被称为“快照”。“快照”，就类似于拍照，摁下快门那一刻，所定格的照片，就称为“快照”。Redis有4种情况会对数据进行快照： 根据配置规则进行自动快照 用户执行SAVE或BGSAVE命令 执行FLUSHALL命令 执行复制（replication）时 根据配置规则进行自动快照配置文件的自定义信息由两个参数决定：时间窗口M和改动的键的个数。 如配置：save 900 1 可以配置多个快照条件，每条快照条件都占一行，并且以save开头，上面这条表示900秒内有一个或一个以上的键被修改了，就进行快照。 用户执行SAVE或BGSAVE命令在执行SAVE命令进行手动快照时，快照过程中会阻塞所有来自客户端的请求，当数据库数据比较多时，那么这一过程就会使得客户端等待较长的时间；相对的，执行BGSAVE命令时，则是采用异步快照，在进行快照过程中，依然响应来自客户端的请求。所以，比较常用的是BGSAVE命令。 执行FLUSHALL命令当执行FLUSHALL命令时，Redis会清除数据库的所有数据。值得注意的是，清空数据库过程，相当于修改键，在这个过程中，只要自动快照条件不为空，Redis都会执行一次快照，换句话说，如果没有定义自动快照条件时，即使执行了FLUSHALL命令，也不会进行快照。 执行复制（replication）当设置了主从模式时，Redis会在复制初始化时进行自动快照。这里跟FLUSHALL有区别，执行复制时，即使没有设置自动快照条件，也会进行快照操作，生成RDB格式文件。 快照原理Redis默认会将快照文件存储在Redis当前进程的工作目录中的dump.rdb文件中，可以配置 dir和dbfilename两个参数设置快照文件路径。快照过程： Redis使用fork函数复制一份当前进程的副本； 父进程（这里是当前进程）继续接收并处理客户端发来的命令，而子进程（副本）开始将内存中的数据写入硬盘中临时文件； 当子进程写完所有数据后，就用临时文件覆盖掉旧的RDB文件，至此，完成一次快照操作。 在fork函数执行的时候，操作系统会使用写时复制（copy-on-write）策略，即fork函数发生的那一刻，父子进程共享同一内存数据，当父进程要更改其中某片数据时，操作系统会将该片数据复制一份，以保证子进程不受影响，所以新的RDB格式文件保存的是执行fork那一刻的内存数据。因为使用了写时复制策略，使得在fork的时刻用了不到2倍的内存，就可以保存貌似两份的内存副本一样。 123值得注意的是: 当进行快照的过程中，如果写入操作较多，造成fork前后数据差异较大，是会使得内存使用量显著增加，因为内存中不仅保存当前进程的数据，还保存了fork时刻的内存数据. Redis进行快照的过程中不会修改RDB文件, 只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的，这对于数据库备份有一个很好的作用 AOF方式通过RDB方式实现持久化，一旦Redis异常退出，，就会丢失最后一次快照之后更改的所有数据。为了降低因进程中止导致的数据丢失风险，可以使用AOF方式实现数据持久化。 默认情况下，Redis是没有开启AOF方式的持久化，可以通过appendonly参数启动：appendonly yes 开启AOF持久化后，每执行一条会更改Redis中数据的命令，Redis就会将该命令写入硬盘中的AOF格式的文件，即.aof格式文件存储的是一些redis指令。这个时候就要注意，当频繁操作Redis中的数据时，AOF格式文件所占内存就会越来越大，而且会有很多没用的指令，如连续执行set foo 1，set foo 2，set foo 3，那么前两条指令是没有意义的，Redis很强大，它会自动将没有意义的指令删除，即每当达到一定条件时，Redis就会自动重写AOF文件，而这个条件可以在配置文件中设置。重写的过程只和内存数据有关，和之前的AOF文件无关，这点跟RDB相似。 在同步硬盘数据数据时，由于操作系统的缓存机制，数据并没有真正地写入到硬盘中，而是进入到系统的硬盘缓存。在默认的情况下，系统每个30秒会执行一次同步操作，在这30秒的过程中，如果系统异常退出，那么会导致硬盘内存中的数据丢失。Redis允许同时开启RDB和AOF方式，既保证了数据安全，又使得备份操作十分容易。AOF可以有效降低数据丢失的可能性，RDB可以使得数据备份容易达到。","categories":[{"name":"redis","slug":"redis","permalink":"http://qiaofengfangxh.top/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://qiaofengfangxh.top/tags/redis/"}]},{"title":"MySQL 性能优化神器 Explain 使用分析","slug":"MySQL性能优化神器Explain使用分析","date":"2020-07-15T10:30:16.000Z","updated":"2020-07-30T01:41:17.974Z","comments":true,"path":"2020/07/15/MySQL性能优化神器Explain使用分析/","link":"","permalink":"http://qiaofengfangxh.top/2020/07/15/MySQL性能优化神器Explain使用分析/","excerpt":"","text":"介绍MySQL 提供了一个 EXPLAIN 命令, 它可以对 SELECT 语句进行分析,并输出 SELECT 执行的详细信息, 以供开发人员针对性优化.EXPLAIN 命令用法十分简单,在 SELECT 语句前加上 Explain 就可以了, 例如:EXPLAIN SELECT * from user_info WHERE id &lt; 300; 准备工作为了接下来方便演示 EXPLAIN 的使用, 首先我们需要建立两个测试用的表, 并添加相应的数据: 创建用户表 12345678910111213141516171819CREATE TABLE `user_info`( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `name` VARCHAR(50) NOT NULL DEFAULT '', `age` INT(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `name_index` (`name`));ENGINE = InnoDB;DEFAULT CHARSET = utf8;INSERT INTO user_info (name, age) VALUES ('xys', 20);INSERT INTO user_info (name, age) VALUES ('a', 21);INSERT INTO user_info (name, age) VALUES ('b', 23);INSERT INTO user_info (name, age) VALUES ('c', 50);INSERT INTO user_info (name, age) VALUES ('d', 15);INSERT INTO user_info (name, age) VALUES ('e', 20);INSERT INTO user_info (name, age) VALUES ('f', 21);INSERT INTO user_info (name, age) VALUES ('g', 23);INSERT INTO user_info (name, age) VALUES ('h', 50);INSERT INTO user_info (name, age) VALUES ('i', 15); 创建订单表 12345678910111213141516171819CREATE TABLE `order_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `user_id` BIGINT(20) DEFAULT NULL, `product_name` VARCHAR(50) NOT NULL DEFAULT '', `productor` VARCHAR(30) DEFAULT NULL, PRIMARY KEY (`id`), KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`));ENGINE = InnoDB;DEFAULT CHARSET = utf8;INSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p2', 'WL');INSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p1', 'DX');INSERT INTO order_info (user_id, product_name, productor) VALUES (2, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (2, 'p5', 'WL');INSERT INTO order_info (user_id, product_name, productor) VALUES (3, 'p3', 'MA');INSERT INTO order_info (user_id, product_name, productor) VALUES (4, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (6, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (9, 'p8', 'TE'); EXPLAIN 输出格式EXPLAIN 命令的输出内容大致如下:explain select * from user_info where id = 2 执行结果 EXPLAIN 各列的含义 id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符 select_type: SELECT 查询的类型 table: 查询的是哪个表 partitions: 匹配的分区 type: join 类型 possible_keys: 此次查询中可能选用的索引 key: 此次查询中确切使用到的索引 ref: 哪个字段或常数与 key 一起被使用 rows: 显示此查询一共扫描了多少行. 这个是一个估计值 filtered: 表示此查询条件所过滤的数据的百分比 extra: 额外的信息 EXPLAIN 重要字段比较select_type select_type 表示了查询的类型, 它的常用取值有: SIMPLE：表示此查询不包含 UNION 查询或子查询 PRIMARY：表示此查询是最外层的查询 UNION：表示此查询是 UNION 的第二或随后的查询 DEPENDENT UNION：UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT：UNION 的结果 SUBQUERY：子查询中的第一个 SELECT DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果 最常见的查询类别应该是 SIMPLE 了, 比如当我们的查询没有子查询, 也没有 UNION 查询时, 那么通常就是 SIMPLE 类型, 例如: explain select * from user_info where id = 2 执行结果 如果我们使用了 UNION 查询, 那么 EXPLAIN 输出 的结果类似如下: EXPLAIN (SELECT * FROM user_info WHERE id IN (1, 2, 3)) UNION (SELECT * FROM user_info WHERE id IN (3, 4, 5)); UNION执行结果 table表示查询涉及的表或衍生表 typetype 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 type 字段, 我们判断此次查询是 全表扫描 还是 索引扫描 等. type的常用类型type 常用的取值有: system: 表中只有一条数据. 这个类型是特殊的 const 类型. const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可.例如下面的这个查询, 它使用了主键索引, 因此 type 就是 const 类型的. explain select * from user_info where id = 2 执行结果 eq_ref: 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =, 查询效率较高例如查询: EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id 执行结果 ref: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询.例如下面这个例子中, 就使用到了 ref 类型的查询:EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id AND order_info.user_id = 5 执行结果 range: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中. 当 type 是 range 时, 那么 EXPLAIN 输出的 ref 字段为 NULL, 并且 key_len 字段是此次查询中使用到的索引的最长的那个.例如下面的例子就是一个范围查询: EXPLAIN SELECT * FROM user_info WHERE id BETWEEN 2 AND 8 执行结果 index: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据. index 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 Using index.例如下面的查询:我们查询的 name 字段恰好是一个索引, 因此我们直接从索引中获取数据就可以满足查询的需求了, 而不需要查询表中的数据. 因此这样的情况下, type 的值是 index, 并且 Extra 的值是 Using index, 比如：EXPLAIN SELECT name FROM user_info 执行结果 ALL: 表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免.例如下面的查询: 可以看到, 在全表扫描时, possible_keys 和 key 字段都是 NULL, 表示没有使用到索引, 并且 rows 十分巨大, 因此整个查询效率是十分低下的，比如：EXPLAIN SELECT age FROM user_info WHERE age = 20 执行结果 type 类型的性能比较.通常来说, 不同的 type 类型的性能关系如下: ALL &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; system. ALL 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.而 index 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快.后面的几种类型都是利用了索引来查询数据, 因此可以过滤部分或大部分数据, 因此查询效率就比较高了. possible_keyspossible_keys 表示 MySQL 在查询时, 能够使用到的索引. 注意, 即使有些索引在 possible_keys 中出现, 但是并不表示此索引会真正地被 MySQL 使用到. MySQL 在查询时具体使用了哪些索引, 由 key 字段决定. key此字段是 MySQL 在当前查询时所真正使用到的索引. key_len表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到. rowsrows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数.这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好. ExtraEXplain 中的很多额外的信息会在 Extra 字段显示, 常见的有以下几种内容: Using filesort当 Extra 中有 Using filesort 时, 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 一般有 Using filesort, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大. Using index“覆盖索引扫描”, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错. Using temporary查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化.","categories":[{"name":"mysql","slug":"mysql","permalink":"http://qiaofengfangxh.top/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://qiaofengfangxh.top/tags/mysql/"},{"name":"sql优化","slug":"sql优化","permalink":"http://qiaofengfangxh.top/tags/sql优化/"},{"name":"索引学习","slug":"索引学习","permalink":"http://qiaofengfangxh.top/tags/索引学习/"}]},{"title":"MySQL-数据库引擎","slug":"MySQL-数据库引擎","date":"2020-07-11T10:30:16.000Z","updated":"2020-07-30T01:41:05.498Z","comments":true,"path":"2020/07/11/MySQL-数据库引擎/","link":"","permalink":"http://qiaofengfangxh.top/2020/07/11/MySQL-数据库引擎/","excerpt":"","text":"数据库引擎是用于存储、处理和保护数据的核心服务。利用数据库引擎可控制访问权限并快速处理事务，从而满足企业内大多数需要处理大量数据的应用程序的要求。 使用数据库引擎创建用于联机事务处理或联机分析处理数据的关系数据库。这包括创建用于存储数据的表和用于查看、管理和保护数据安全的数据库对象（如索引、视图和存储过程）等。 MySQL数据库引擎类别MySql数据库引擎取决于mysql在安装的时候是如何被编译的。要添加一个新的引擎，就必须重新编译MYSQL。在缺省情况下，MYSQL支持三个引擎：ISAM、MYISAM和HEAP。另外两种类型INNODB，特别说明：MySQL的默认‘存储引擎’在5.5版本以前是MYISAM，之后是INNODB。 ISAMISAM是一个定义明确且历经时间考验的数据表格管理方法，它在设计之时就考虑到数据库被查询的次数要远大于更新的次数。因此，ISAM执行读取操作的速度很快，而且不占用大量的内存和存储资源。ISAM的两个主要不足之处在于，它不支持事务处理，也不能够容错：如果你的硬盘崩溃了，那么数据文件就无法恢复了。如果你正在把ISAM用在关键任务应用程序里，那就必须经常备份你所有的实时数据，通过其复制特性，MYSQL能够支持这样的备份应用程序 MYISAMMYISAM是MYSQL的ISAM扩展格式和缺省的数据库引擎。除了提供ISAM里所没有的索引和字段管理的功能，MYISAM还使用一种表格锁定的机制，来优化多个并发的读写操作。其代价是你需要经常运行OPTIMIZE TABLE命令，来恢复被更新机制所浪费的空间。MYISAM还有一些有用的扩展，例如用来修复数据库文件的MYISAMCHK工具和用来恢复浪费空间的MYISAMPACK工具。 MYISAM强调了快速读取操作，这可能就是为什么MYSQL受到了WEB开发如此青睐的主要原因：在WEB开发中你所进行的大量数据操作都是读取操作。所以，大多数虚拟主机提供商和INTERNET平台提供商只允许使用MYISAM格式。 HEAPHEAP允许只驻留在内存里的临时表格。驻留在内存里让HEAP要比ISAM和MYISAM都快，但是它所管理的数据是不稳定的，而且如果在关机之前没有进行保存，那么所有的数据都会丢失。在数据行被删除的时候，HEAP也不会浪费大量的空间。HEAP表格在你需要使用SELECT表达式来选择和操控数据的时候非常有用。要记住，在用完表格之后就删除表格。 INNODB和BERKLEYDBINNODB和BERKLEYDB（BDB）数据库引擎都是造就MYSQL灵活性的技术的直接产品，这项技术就是MYSQL++ API。在使用MYSQL的时候，你所面对的每一个挑战几乎都源于ISAM和MYISAM数据库引擎不支持事务处理也不支持外来键。尽管要比ISAM和MYISAM引擎慢很多，但是INNODB和BDB包括了对事务处理和外来键的支持，这两点都是前两个引擎所没有的。 mysql数据引擎更换方式查看当前数据库支持的引擎和默认的数据库引擎1show engines; 查询结果如下： 更改数据库引擎更改数据库引擎有以下3种方法，如下： 修改配置文件my.ini 1将my-small.ini另存为my.ini，在[mysqld]后面添加default-storage-engine=InnoDB，重启服务，数据库默认的引擎修改为InnoDB 建表的时候指定 1234create table mytbl( id int primary key, name varchar(50) )type=MyISAM; 建表后更改 1alter table mytbl2 type = InnoDB; 查看修改结果1show table status from `数据库名称` MyIASM和Innodb引擎对比存储结构 MyISAM：每个MyISAM在磁盘上存储成三个文件。分别为：表定义文件、数据文件、索引文件。第一个文件的名字以表的名字开始，扩展名 指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。 InnoDB：所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件 的大小，一般为2GB。 存储空间 MyISAM：MyISAM支持支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。当表在创 建之后并导入数据之后，不会再进行修改操作，可以使用压缩表，极大的减少磁盘的空间占用。 InnoDB：需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。 可移植性、备份及恢复 MyISAM：数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。 InnoDB：免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。 事务支持 MyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。 InnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。 主键自增AUTO_INCREMENT和主键索引差异 MyISAM：可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前 面几列进行排序后递增。 InnoDB：InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。 表主键 MyISAM：允许没有任何索引和主键的表存在，索引都是保存行的地址。 表主键 InnoDB：如果没有设定主键或者非空唯一索引，就会自 动生成一个6字节的主键(用户不可见，数据是主索引的一部分，附加索引保存的是主索引的值，InnoDB的主键范围更大，最大 是MyISAM的2倍）。 表锁对比 MyISAM： 只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表 满足insert并发的情况下，可以在表的尾部插入新的数据。 InnoDB： 支持事务和行级锁，是innodb的最大特色，行锁大幅度提高了多用户并发操作的新能，但是InnoDB的行锁，只是在WHERE的 主键是有效的，非主键的WHERE都会锁全表的。 MySql全文索引 MyISAM：支持 FULLTEXT类型的全文索引。 InnoDB：不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。 特别说明：InnoDB引擎对FULLTEXT索引的支持是MySQL5.6新引入的特性，之前只有MyISAM引擎支持FULLTEXT索引。对于FULLTEXT索引的内容可以使用MATCH()…AGAINST语法进行查询。但是无法支持中文全文索引，参考1, MySQL5.7版本开始支持中文全文索引，参考2 表的具体行数 MyISAM： 保存有表的总行数，如果select count() from table;会直接取出出该值。 InnoDB： 没有保存表的总行数，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了wehre条件 后，myisam和innodb处理的方式都一样。 CRUD操作 MyISAM：如果执行大量的SELECT，MyISAM是更好的选择。 InnoDB：如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。 外键支持 MyISAM：不支持。 InnoDB：支持。 总结MyISAM 强调的是性能，每次查询具有原子性,其执行速度比InnoDB类型更快，但是不提供事务支持。但是InnoDB 提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力的事务安全(ACID)型表。MyISAM更适合读密集的表，而InnoDB更适合写密集的的表，另外MyISAM的索引与行记录是分开存储的，叫做非聚集索引（UnClustered Index), InnoDB的主键索引与行记录是存储在一起的，故叫做聚集索引（Clustered Index)。","categories":[{"name":"mysql","slug":"mysql","permalink":"http://qiaofengfangxh.top/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://qiaofengfangxh.top/tags/mysql/"},{"name":"数据库引擎","slug":"数据库引擎","permalink":"http://qiaofengfangxh.top/tags/数据库引擎/"},{"name":"聚集索引和非聚集索引","slug":"聚集索引和非聚集索引","permalink":"http://qiaofengfangxh.top/tags/聚集索引和非聚集索引/"}]},{"title":"Java虚拟机中的垃圾回收算法与垃圾收集器","slug":"Java虚拟机中的垃圾回收算法与垃圾收集器","date":"2020-07-05T07:30:16.000Z","updated":"2020-07-30T01:40:52.338Z","comments":true,"path":"2020/07/05/Java虚拟机中的垃圾回收算法与垃圾收集器/","link":"","permalink":"http://qiaofengfangxh.top/2020/07/05/Java虚拟机中的垃圾回收算法与垃圾收集器/","excerpt":"","text":"什么是垃圾回收在程序的运行过程中，我们所创建的对象都会申请内存资源，当这个对象没有用处的时候，我们就需要将它的内存资源释放，否则造成内存资源的浪费，所以我们需要对内存资源进行管理。 在C/C++语言中，没有自动的垃圾回收机制，通过手动申请内存资源及手动释放内存资源来达到内存资源的控制，如果没有手动释放资源，则申请的对象占用的内存资源会一直占用，最终可能会导致内存溢出。 为了使得我们可以更专注与代码的实现而不用过多的考虑内存资源释放的问题，就需要一个垃圾回收机制来帮助我们在合速的时间，进行对垃圾对象的内存资源回收，将垃圾对象的内存资源释放。 什么对象是垃圾我们创建的对象实例都是放在Java堆中的，所以垃圾收集器的大部分时间也是在堆中的，垃圾收集器会判断堆中的哪些对象还在使用，哪些对象是垃圾，可以被回收。 方法区中也可以进行垃圾收集，回收废弃常量及无用的类，但是方法区中的垃圾收集性价比太低，所以在Java虚拟机规范中也不要求虚拟机在方法区实现垃圾收集。 引用计数法引用计数法是一个很经典的垃圾收集算法，它的实现很简单，就是给对象添加一个引用的计数器，有其他地方引用它时，计数器的值就增加1，当引用失效时，这个引用就减1。当对象的引用计数器为0时，这个对象就是不可能再被使用的状态。 如上图，对象A不再引用对象B后，对象B的引用计数器就会减1且到达0值，这时对象B不会再被其他任何对象使用到了，所以对象B需要被回收。 引用计数法的判断效率很高，在大部分情况下效果其实都不错，但是它确有个大问题，也就是引用计数法无法解决对象之间相互循环引用的问题。 如上图，实际上对象B和对象C已经不会再被使用到了，但是对象B和对象C的引用计数器都不为0。 可达性分析法在Java虚拟机的主流实现中，一般都是通过可达性分析来判断对象是否为垃圾。可达性分析法的基本思路为通过一系列被称为GC Roots的对象为起始点，从这些节点向下搜索，搜索到的路径称为引用链，如果一个对象到GC Roots没有任何引用链时，则说明这个对象是不可用的对象，可以被回收。 如下图，对象D、对象E、对象F虽然有引用关系，但是他们到GC Roots没有任何引用链，是不可达的对象，所以它们会被判断为可回收的对象。 在Java中，可作为GC Roots的对象包括下面几种： Java栈和本地方法栈中引用的对象 方法区中类静态属性和常量引用的对象 java中的四种引用在判断对象是否是垃圾时，无论是引用计数法和可达性分析法，都是与引用有关。如果一个对象只有被引用和没有被引用两种状态，那么我们对于对象的引用操作空间就很小，例如我们希望在内存空间充足的时候保存一些对象，但是在内存资源比较紧缺的时候可以抛弃这些对象，这样的应用场景可以用在缓存上。 在JDK 1.2之后，Java对引用的概念进行了扩充，将引用分为了强引用、软引用、弱引用、虚引用4种引用。 强引用 (StrongReference)强引用是指在程序代码中普遍存在的，类似Object obj=new Object()这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。只要某个对象有强引用与之关联，JVM必定不会回收这个对象，即使在内存不足的情况下，JVM宁愿抛出OutOfMemory错误也不会回收这种对象。 软引用 (SoftReference)软引用是用来描述一些有用但并不是必需的对象。对于软引用关联着的对象，只有在内存不足的时候JVM才会回收该对象。因此，这一点可以很好地用来解决OOM的问题，并且这个特性很适合用来实现缓存：比如网页缓存、图片缓存等。JDK 1.2之后，提供了SoftReference类来实现软引用。 123456789import java.lang.ref.SoftReference; public class Main &#123; public static void main(String[] args) &#123; //创建一个软引用的对象 SoftReference&lt;String&gt; sr = new SoftReference&lt;String&gt;(new String(\"hello\")); System.out.println(sr.get()); &#125;&#125; 弱引用 (WeakReference）弱引用也是用来描述非必需对象的，当JVM进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象 1234567891011import java.lang.ref.WeakReference; public class Main &#123; public static void main(String[] args) &#123; WeakReference&lt;String&gt; sr = new WeakReference&lt;String&gt;(new String(\"hello\")); System.out.println(sr.get()); //通知JVM的gc进行垃圾回收 System.gc(); System.out.println(sr.get()); &#125;&#125; 输出结果: 12hellonull 虚引用（PhantomReference）一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来获取一个对象的实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。并且，虚引用必须和引用队列一起使用，它的作用在于跟踪垃圾回收过程。 当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在垃圾回收后，销毁这个对象。 1234567891011import java.lang.ref.PhantomReference;import java.lang.ref.ReferenceQueue; public class Main &#123; public static void main(String[] args) &#123; ReferenceQueue&lt;String&gt; queue = new ReferenceQueue&lt;String&gt;(); PhantomReference&lt;String&gt; pr = new PhantomReference&lt;String&gt;(new String(\"hello\"), queue); System.out.println(pr.get()); &#125;&#125; 总结 对比 强引用 软引用 弱引用 虚引用 引用强度 最强 第二 第三 第四 如何使用 new Object() SoftReference WeakReference PhantomReference 对象复生finalize方法如果对象实现了finalize()方法，且该方法还未被虚拟机调用过，那么这个对象在回收前会被加入F-Queue的队列中，在稍后由一个虚拟机建立的低优先级的Finalizer线程去执行。但虚拟机虽然会触发这个方法，但并不保证这个方法的执行结束，防止这个方法的执行过程太慢或者发生死循环等情况导致队列中的其他对象处于等待。 对象的finalize()方法只能被调用一次，如果在下一次被回收时对象的finalize()方法已经被调用过了，那么该方法不会再次执行，而且这个方法也是不建议使用的方法，我们往往有更好的方案来替代它。 垃圾收集算法各个平台的虚拟机操作内存的方法细节可能会有不同，但是垃圾收集的算法思路都是类似的。 标记清除法标记清除法是垃圾回收算法中的思想基础，标记清除法将垃圾回收分为标记和清除两个阶段。首先标记出从根节点开始可达的对象，未标记的对象就是可回收的对象，然后将这些对象进行回收。 但是标记清除法的最大问题就是会产生大量不连续的空间碎片，如下图所示，回收后的空间是不连续的： 复制算法复制算法算法将原有的内存空间分为两块，每次只使用其中的一块，在垃圾回收时，将还存活着的对象复制到另外一块上面，然后将这一块内存空间的所有对象清除。 如果垃圾对象很多，需要复制的存活对象数量就会相对较少，因此复制算法的效率还是很高的，并且将对象复制到新的内存空间中也保证了不会有空间碎片的存在；但是复制算法的代价是将内存折半。 如下图，将内存空间分为A、B两块，在A进行垃圾回收时，将A空间中的存活对象复制到B中，并将A空间清空： 在大多数时候采用复制算法来回收年轻代中的垃圾对象，而且因为大部分的对象死亡周期非常短暂，所以可以不用直接将内存折半，而是将内存使用8:1:1的比例分为了一个较大的Eden空间及2块Survivor空间。 当进行垃圾回收时，将Eden空间和Survivor空间中存活的对象复制到另一块Survivor空间上，然后清除Eden空间和刚刚使用的Survivor空间。每次使用的内存比例达到了百分之九十，只有百分之十的Survivor空间作为被复制的内存空间，每次复制后，两个Survivor空间的角色互换。 当Survivor空间的内存不够将对象复制进来时，需要老年代进行分配担保。也就是另外Survivor空间没有足够的内存存放收集到的存活对象时，这些对象直接会进入老年代。 标记压缩法复制算法如果在对象的存活率较高时，效率就会变低，在老年代中，大部分对象都是存活对象，所以复制算法的成本就会提高，所以基于老年代对象的特性，就需要使用其他算法。 基于老年代对象的特性，标记压缩法是在标记清除法的基础上优化得来的一直垃圾回收算法。和标记清除的过程一样，首先标记存活的对象，但之后并不是简单的清理未标记的对象，而是将存活的对象压缩到内存的一端。之后清理边界外的所有空间。 这种方法避免了空间碎片的产生，也不需要两块内存空间，因此性价比较高，标记压缩法的过程如下图所示： 垃圾收集器在Java虚拟机中，在什么情况下要使用什么类型的垃圾收集器以及这些垃圾收集器会造成什么样的影响，这是是我们需要了解的，只有了解了这些垃圾收集器的特点和使用方法，我们才能在具体的应用中使用合适的垃圾收集器。 串行收集器串行收集器是使用单线程进行垃圾回收的垃圾收集器，并且在进行垃圾回收时，必须暂停其他所有的工作线程，知道串行收集器的垃圾回收结束。 串行收集器可以在年轻代及老年代的内存空间中进行垃圾回收，如下图所示，串行收集器在工作时，应用程序中的所有线程都需要停止工作，这种现象被称为Stop The World。 年轻代的串行收集器采用复制算法进行回收，老年代的串行收集器采用标记压缩法进行回收，串行收集器的实现相对简单且不用进行线程切换。在单CPU的硬件下性能还不错。 并行收集器并行收集器是串行收集器的多线程版本，并行收集器使用多个线程同时进行垃圾回收，对于并行能力较强的硬件情况下可以提高性能。 并行收集器同样可以在年轻代及老年代的内存空间中进行垃圾回收，回收策略与使用的算法都与串行收集器一样。 并行收集器工作过程如下图所示： 并行收集器由于存在线程交互的开销，在单CPU的环境中，串行收集器的效果会更好。但是随着CPU数量的增加，并行收集器的效率也会随之提升。 Parallel收集器Parallel收集器也可以在年轻代及老年代的内存空间中进行垃圾回收，回收策略与使用的算法都与并行收集器一样，且也是多线程的垃圾收集器。 Parallel收集器的特点是它的关注点与其他收集器不同，Parallel收集器的目标则是达到一个可控制的吞吐量。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 可以在JVM参数中配置Parallel收集器相关的参数进行控制。 CMS收集器CMS收集器是一种以获取最短回收停顿时间为目标的收集器，且在可以在应用程序运行过程中进行垃圾回收。 CMS收集器是基于标记清除法实现的，它的运作步骤如下： 初始标记，标记根对象 并发标记，标记回收对象 预处理，清理垃圾对象前的装备及控制停顿时间，也可以关闭预处理步骤 重新标记，修改并发标记中的对象 并发清除，清除垃圾其中，初始标记、重新标记这两个步骤仍然需要Stop The World。 初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。 整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作的，下图比较清楚地展示了CMS收集器的运作步骤中并发和需要停顿的时间： CMS是一款优秀的收集器，它的主要优点就是并发收集及低停顿。但是CMS对CPU资源的要求较高且会出现大量的空间碎片。 G1收集器G1收集器对内存进行了分区，虽然也会区分年轻代和老年代，但是G1对内存中的对象进行分区的回收，同时，G1收集器的特点如下： 并行与并发：G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短Stop-The-World停顿的时间，并且G1收集器的部分工作可以和应用程序同时运行。 分代收集：G1收集器能够同时管理年轻代和老年代，其他收集器都需要根据算法的不同为年轻代和老年代使用不同的垃圾收集器。 空间整理：G1从整体来看是基于标记压缩法实现的收集器，从分区上来看是基于复制算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行。 可预测性：G1可以只选择部分分区进行垃圾回收，达到对全局停顿的控制。在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代。而G1收集器的Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立分区（Region）。 G1收集器的内存模型如下： 在G1收集器中，使用记忆集合(Remembered Set，简称RSet)来避免全堆扫描。每个分区都有一个RSet，程序在对引用对象类型的数据进行写操作时，会产生一个Write Barrier(屏障)暂时中断写操作，检查这个引用的对象是否处于不同的分区之中；如果是，便把相关引用信息记录到被引用对象所属的分区的RSet之中。进行内存回收时，在GC根节点的枚举范围中加入RSet即可保证不对全堆扫描也不会有遗漏。 每个分区会被分为多个Card，所以在RSet中会记录对应分区中的Card，如下图所示： G1收集器的运作大致可划分为以下几个步骤： 初始标记，标记根对象 并发标记，标记回收对象 重新标记，修改并发标记中的对象 分区清理 其中，初始标记、重新标记这两个步骤和CMS收集器一样仍然需要Stop The World,在重新标记阶段会重新更新对象的记忆集合(Remembered Set)，最后在分区清理阶段首先对各个分区的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，根据区域的优先级进行回收。","categories":[{"name":"java","slug":"java","permalink":"http://qiaofengfangxh.top/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://qiaofengfangxh.top/tags/JVM/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"http://qiaofengfangxh.top/tags/垃圾回收/"},{"name":"java的4种引用","slug":"java的4种引用","permalink":"http://qiaofengfangxh.top/tags/java的4种引用/"}]},{"title":"Java设计模式-策略模式","slug":"Java设计模式-策略模式","date":"2020-06-28T07:30:16.000Z","updated":"2020-07-30T01:40:32.384Z","comments":true,"path":"2020/06/28/Java设计模式-策略模式/","link":"","permalink":"http://qiaofengfangxh.top/2020/06/28/Java设计模式-策略模式/","excerpt":"","text":"策略模式（Pattern:Strategy）属于行为型模型，是指对一系列的算法定义，并将每一个算法封装起来，而且使它们还可以相互替换。策略模式让算法独立于使用它的客户而独立变化… 定义定义一组算法，将每一个算法封装起来，从而使它们可以相互切换。但是不管切换都是为了实现一致的目标任务。 特点 一组算法，那就是不同的策略，但是这些不同的算法都是为了实现同一个目标任务 这组算法都实现了相同的接口或者继承相同的抽象类，所以可以相互切换 UML图 java设计模式——策略模式 策略模式的角色 封装角色：上层访问策略的入口，它持有抽象策略角色的引用 抽象策略角色：提供接口或者抽象类，定义策略组必须拥有的方法和属性 具体策略角色：实现抽象策略，定义具体的算法逻辑 实战案例演示比如从杭州到上海，我们可以选择三种交通方式，第一种是高铁，第二种是飞机，第三种是出租车，所以我们为了达到从杭州去上海的目标任务，可以通过定义这三种策略算法。 抽象策略类123456789101112package com.qiaofengfangxh.study;/** * 抽象策略接口 * @author fangxh */public interface IStrategy &#123; /** * 杭州到上海去的目标任务 */ void hangToShangHai();&#125; 具体策略类123456789101112package com.qiaofengfangxh.study;/** * 飞机策略 * @author fangxh */public class PlaneStrategy implements IStrategy &#123; public void hangToShangHai() &#123; System.out.println(\"------这是从上海到杭州做【飞机】的交通方式------\"); &#125;&#125; 123456789101112package com.qiaofengfangxh.study;/** * 出租车策略 * @author fangxh */public class TaxiStrategy implements IStrategy &#123; public void hangToShangHai() &#123; System.out.println(\"------这是从上海到杭州做【出租车】的交通方式------\"); &#125;&#125; 123456789101112package com.qiaofengfangxh.study;/** * 火车策略 * @author fangxh */public class TrainStrategy implements IStrategy &#123; public void hangToShangHai() &#123; System.out.println(\"------这是从上海到杭州做【火车】的交通方式------\"); &#125;&#125; 上下文类12345678910111213141516171819202122232425package com.qiaofengfangxh.study;/** * 包装策略的上下文类 * @author fangxh */public class Context &#123; private IStrategy strategy; /** * 传进的是一个具体的策略实例 * @param strategy */ public Context(IStrategy strategy) &#123; this.strategy = strategy; &#125; /** * 调用策略 */ public void doStrategy() &#123; strategy.hangToShangHai(); &#125;&#125; 测试类1234567891011121314151617181920212223package com.qiaofengfangxh.study;/** * 客户端测试类 * @author fangxh */public class Client &#123; public static void main(String[] args) &#123; //策略1 Context context = new Context(new PlaneStrategy()); context.doStrategy(); //策略2 context = new Context(new TaxiStrategy()); context.doStrategy(); //策略3 context = new Context(new TrainStrategy()); context.doStrategy(); &#125;&#125; 执行结果123------这是从上海到杭州做【飞机】的交通方式------------这是从上海到杭州做【出租车】的交通方式------------这是从上海到杭州做【火车】的交通方式------ 策略模式的优缺点优点 良好的扩展性。增加一种策略，只要实现接口，写上具体逻辑就可以了。当旧策略不需要时，直接剔除就行。 良好的封装性。策略的入口封装在Context封装类中，客户端只要知道使用哪种策略就传哪种策略对象就可以了。 避免了像简单工厂模式这样的多重条件判断。 缺点 客户端必须了解策略组的各个策略，并且决定使用哪一个策略，也就是各个策略需要暴露给客户端。 如果策略增多，策略类的数量就会增加。 适用场景 同一抽象类有多个子类，并且需要使用if-else或switch-case选择具体子类时。 封装同一类型操作的不同算法，对使用算法的客户隐藏具体算法的实现细节。 针对同一类型问题的多种操作，仅仅是操作行为不同，并且将来可能会增加新的操作。","categories":[{"name":"java","slug":"java","permalink":"http://qiaofengfangxh.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://qiaofengfangxh.top/tags/java/"},{"name":"设计模式","slug":"设计模式","permalink":"http://qiaofengfangxh.top/tags/设计模式/"},{"name":"策略模式","slug":"策略模式","permalink":"http://qiaofengfangxh.top/tags/策略模式/"}]}],"categories":[{"name":"java","slug":"java","permalink":"http://qiaofengfangxh.top/categories/java/"},{"name":"redis","slug":"redis","permalink":"http://qiaofengfangxh.top/categories/redis/"},{"name":"mysql","slug":"mysql","permalink":"http://qiaofengfangxh.top/categories/mysql/"}],"tags":[{"name":"java","slug":"java","permalink":"http://qiaofengfangxh.top/tags/java/"},{"name":"设计模式","slug":"设计模式","permalink":"http://qiaofengfangxh.top/tags/设计模式/"},{"name":"观察者模式","slug":"观察者模式","permalink":"http://qiaofengfangxh.top/tags/观察者模式/"},{"name":"线程池","slug":"线程池","permalink":"http://qiaofengfangxh.top/tags/线程池/"},{"name":"redis","slug":"redis","permalink":"http://qiaofengfangxh.top/tags/redis/"},{"name":"mysql","slug":"mysql","permalink":"http://qiaofengfangxh.top/tags/mysql/"},{"name":"sql优化","slug":"sql优化","permalink":"http://qiaofengfangxh.top/tags/sql优化/"},{"name":"索引学习","slug":"索引学习","permalink":"http://qiaofengfangxh.top/tags/索引学习/"},{"name":"数据库引擎","slug":"数据库引擎","permalink":"http://qiaofengfangxh.top/tags/数据库引擎/"},{"name":"聚集索引和非聚集索引","slug":"聚集索引和非聚集索引","permalink":"http://qiaofengfangxh.top/tags/聚集索引和非聚集索引/"},{"name":"JVM","slug":"JVM","permalink":"http://qiaofengfangxh.top/tags/JVM/"},{"name":"垃圾回收","slug":"垃圾回收","permalink":"http://qiaofengfangxh.top/tags/垃圾回收/"},{"name":"java的4种引用","slug":"java的4种引用","permalink":"http://qiaofengfangxh.top/tags/java的4种引用/"},{"name":"策略模式","slug":"策略模式","permalink":"http://qiaofengfangxh.top/tags/策略模式/"}]}